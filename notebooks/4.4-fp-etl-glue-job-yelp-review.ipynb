{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LvSFjIMkHbZuidPd2ZNQMq_cVOxHAkg0",
      "authorship_tag": "ABX9TyPMtEmJnsJTaaCKHIoTasJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Insights-Labs-Consultant-Agency/yelp-google-maps-reviews-and-recommendations/blob/data-pipeline/notebooks/4.4-fp-etl-glue-job-yelp-review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción, transformación y carga (ETL)"
      ],
      "metadata": {
        "id": "hNl1vrW1wxib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook, nuestro objetivo es realizar el proceso de extracción, transformación y carga (ETL) de los datos de Yelp y Google Maps utilizando la librería AWS Glue 3.0 que servirá como base para los scripts de los diferentes ETL Glue Jobs que se usaran en AWS Glue Workflow en el proceso de carga al DW. En esta etapa, se realizará un proceso de limpieza previa y posterior normalización para construir un DER."
      ],
      "metadata": {
        "id": "DDmg3udVw-1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 Configuraciones Globales e Importaciones"
      ],
      "metadata": {
        "id": "4HXp2o_Aytpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección,instalamos e importamos todas las librerías y/o módulos necesarios para nuestro proceso ETL y establecemos configuraciones globales de ser requerido."
      ],
      "metadata": {
        "id": "rh6OIFORyz25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalación de librerías y/o Dependencias"
      ],
      "metadata": {
        "id": "0pZfLw2By_lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-common/apache-maven-3.6.0-bin.tar.gz\n",
        "!tar xvf apache-maven-3.6.0-bin.tar.gz -C /bin/ > /dev/null\n",
        "!wget -q https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-3.0/spark-3.1.1-amzn-0-bin-3.2.1-amzn-3.tgz\n",
        "!tar xvf spark-3.1.1-amzn-0-bin-3.2.1-amzn-3.tgz -C /bin/ > /dev/null\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "enoMebVcsRoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportación de Variables Entorno"
      ],
      "metadata": {
        "id": "bhoxHr9TzVV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] += \":/bin/apache-maven-3.6.0/bin\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/bin/spark-3.1.1-amzn-0-bin-3.2.1-amzn-3/\"\n",
        "os.environ[\"SPARK_CONF_DIR\"] = \"/bin/aws-glue-libs/conf\""
      ],
      "metadata": {
        "id": "zCi3c-5lsX_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalación de AWS GLue 3.0 Libs"
      ],
      "metadata": {
        "id": "uZoM1kz41LQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b glue-3.0 https://github.com/awslabs/aws-glue-libs.git /bin/aws-glue-libs\n",
        "!chmod +x /bin/aws-glue-libs/bin/glue-setup.sh\n",
        "!bash /bin/aws-glue-libs/bin/glue-setup.sh > /dev/null\n",
        "!cp -r /bin/spark-3.1.1-amzn-0-bin-3.2.1-amzn-3/jars/netty-all-4.1.51.Final.jar /bin/aws-glue-libs/jarsv1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ArgNgqsi4I",
        "outputId": "a7e48c7e-8aa1-411a-e5d4-184c9c856a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/bin/aws-glue-libs'...\n",
            "remote: Enumerating objects: 321, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 321 (delta 63), reused 62 (delta 45), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (321/321), 163.93 KiB | 5.12 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "rm: cannot remove 'PyGlue.zip': No such file or directory\n",
            "rm: cannot remove '/bin/aws-glue-libs/conf/spark-defaults.conf': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importación de Librerías y/o Módulos"
      ],
      "metadata": {
        "id": "gs9WyuNY0eIf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weHEFQDDoSoE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d8de2359-d570-4d17-f487-ad95c0be8f60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ceaa433f7c0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9411b472a37f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1-amzn-0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.extend([\"/bin/spark-3.1.1-amzn-0-bin-3.2.1-amzn-3/python\",\"/bin/spark-3.1.1-amzn-0-bin-3.2.1-amzn-3/python/lib/py4j-0.10.9-src.zip\",\"/bin/aws-glue-libs/PyGlue.zip\"])\n",
        "\n",
        "import findspark\n",
        "from awsglue.context import GlueContext\n",
        "from pyspark.context import SparkContext\n",
        "from awsglue.dynamicframe import DynamicFrame\n",
        "from pyspark.sql.functions import split, explode, monotonically_increasing_id\n",
        "\n",
        "findspark.init()\n",
        "sc = SparkContext()\n",
        "glueContext = GlueContext(sc)\n",
        "spark = glueContext.spark_session\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Extracción"
      ],
      "metadata": {
        "id": "f42m4ww00wIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, extraemos los datasets de la fuente y los leemos como un DataFrame de PySpark."
      ],
      "metadata": {
        "id": "RnM8Dls40ytF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo JSON checkin\n",
        "file_path = '/content/drive/MyDrive/data/raw/yelp/review.json'"
      ],
      "metadata": {
        "id": "T-Ftm7L4MXVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lee el archivo JSON con PySpark\n",
        "df = spark.read.json(file_path)"
      ],
      "metadata": {
        "id": "svCYn1oz2AhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Transformación"
      ],
      "metadata": {
        "id": "naOeIpxO919e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, realizamos la limpieza inicial de los datos y las transformaciones necesarias. Esto puede incluir la creación de nuevas columnas  la eliminación de duplicados o columnas innecesarias, la gestión de valores nulos o la corrección de tipos de datos."
      ],
      "metadata": {
        "id": "ua1qTRsQ93hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convierte la columna 'date' al formato datetime\n",
        "df = df.withColumn('date', df['date'].cast('timestamp'))"
      ],
      "metadata": {
        "id": "wplFVIqo5WYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordena el DataFrame por y 'date'\n",
        "df = df.orderBy('date')"
      ],
      "metadata": {
        "id": "xJvgBUPA6bdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambia el nombre de la columna 'stars' por 'rating'\n",
        "df = df.withColumnRenamed('stars', 'rating')"
      ],
      "metadata": {
        "id": "Cu0SOdx-63Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambia el nombre de la columna 'text' por 'review'\n",
        "df = df.withColumnRenamed('text', 'review')"
      ],
      "metadata": {
        "id": "EopP4GKWOTXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reordena las columnas\n",
        "df = df.select('review_id', 'date', 'user_id', 'business_id', 'review', 'rating', 'cool', 'useful', 'funny')\n"
      ],
      "metadata": {
        "id": "giaNOREW8Qrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td6Al7sB5kPn",
        "outputId": "97df6827-b932-46c2-d633-8dede64c9ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+--------------------+--------------------+--------------------+------+----+------+-----+\n",
            "|           review_id|               date|             user_id|         business_id|              review|rating|cool|useful|funny|\n",
            "+--------------------+-------------------+--------------------+--------------------+--------------------+------+----+------+-----+\n",
            "|IykJMMZgbNcUndwf1...|2005-02-16 03:23:22|3zBJUlWtPNoZ0uN83...|2bXm0SynOfxDzfrdr...|It's not chicago ...|   4.0|   0|     0|    0|\n",
            "|-O5ng1XLox6uEr4uI...|2005-02-16 03:29:39|3zBJUlWtPNoZ0uN83...|3g6XqkBikTTbZmTuk...|Great service.  T...|   4.0|   0|     1|    0|\n",
            "|g80vzN72iU03Wh0fS...|2005-02-16 04:06:26|3zBJUlWtPNoZ0uN83...|PP3BBaVxZLcJU54uP...|These guys really...|   5.0|   0|     0|    0|\n",
            "|7Dcrt0Oz0hikA8obG...|2005-03-01 16:57:17|XCsZ3hWa_6oP1WkWv...|U3grYFIeu6RgAAQgd...|Words cannot desc...|   5.0|   0|     0|    0|\n",
            "|WC9q5vhQlQkLK05kE...|2005-03-01 16:59:37|XCsZ3hWa_6oP1WkWv...|Aes-0Q_guDeYewMap...|Food is decent bu...|   2.0|   0|     0|    0|\n",
            "|Q0GJ06L78nkVyNfHr...|2005-03-01 17:25:13|XCsZ3hWa_6oP1WkWv...|CziOtnFSklimJnBgk...|This place gets a...|   3.0|   0|     0|    0|\n",
            "|TYslH-CAecjJxLNs9...|2005-03-01 17:47:15|XCsZ3hWa_6oP1WkWv...|29YqJwOGEuAWqlHZx...|Lovely little res...|   5.0|   0|     0|    0|\n",
            "|b5IWJOAwIKwyOsOGb...|2005-03-01 17:59:26|XCsZ3hWa_6oP1WkWv...|6RBZfirnzE4NahJTn...|This little hole ...|   4.0|   0|     0|    0|\n",
            "|hX0XEpQ0Ai1UgHEQj...|2005-03-01 19:33:35|XCsZ3hWa_6oP1WkWv...|jssubXBNkiSJIhbKu...|This is the origi...|   4.0|   0|     0|    0|\n",
            "|sg2Mc_sanqnZ__lXK...|2005-03-01 19:35:44|XCsZ3hWa_6oP1WkWv...|bSfDI69RkUrodsA1Q...|Oh the Sh*tty Kit...|   5.0|   0|     0|    0|\n",
            "|-wsNpVhc3D-wDmBXR...|2005-03-02 04:53:42|3MYdpmHeNwC6FquRW...|ZPwFVWoiqFOTbnhfS...|Un-safeway.  Meet...|   2.0|   0|     1|    2|\n",
            "|zAt_9VNW7TzeUaDM-...|2005-03-02 22:13:59|B6FbaEEn5Uh4kEqv4...|rtykgAe3cXao_Puzg...|i love the breadb...|   4.0|   0|     0|    0|\n",
            "|jeIAHWWllaXPK-qUj...|2005-03-04 02:06:36|3MYdpmHeNwC6FquRW...|dMGWB4TEfEhgInQef...|Chefs awesome, se...|   5.0|   1|     1|    0|\n",
            "|FfzcGEJ1pYUx8jy0B...|2005-03-04 02:16:43|3MYdpmHeNwC6FquRW...|ajfmcCilbPMKb_Vxs...|A hippie coffee s...|   3.0|   0|     0|    0|\n",
            "|bPC_RuvUUlit5dBbw...|2005-03-04 02:27:33|3MYdpmHeNwC6FquRW...|R3k8rXhJZqsrGDQd-...|Overpriced with s...|   2.0|   0|     1|    2|\n",
            "|h6C67_anU_4EqWqey...|2005-03-04 02:40:25|3MYdpmHeNwC6FquRW...|9zlIJ7Q5W4AENjpGg...|Rated 5 stars for...|   5.0|   1|     0|    0|\n",
            "|mblALCE8KmqBRMjVv...|2005-03-08 04:03:50|3MYdpmHeNwC6FquRW...|8fWtmzdexsuVnxuZx...|Recently changed ...|   3.0|   0|     0|    0|\n",
            "|Lpd82eN3JYDcnLBMY...|2005-03-08 04:35:15|3MYdpmHeNwC6FquRW...|70HV0S-FL7oaiSIN5...|Food is great (ge...|   2.0|   0|     0|    0|\n",
            "|XMhz09Lx8IQz_9Hph...|2005-03-08 05:05:58|58yhbFfNHjULDZx0F...|e5gOtAH36l70fexYy...|One of the top Me...|   5.0|   0|     0|    0|\n",
            "|dCS6vtuFAvwHdEkXs...|2005-03-08 05:10:34|58yhbFfNHjULDZx0F...|J5a2ebSvwIStqCDZE...|For Greek food fa...|   5.0|   0|     0|    0|\n",
            "+--------------------+-------------------+--------------------+--------------------+--------------------+------+----+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeO2moPrMm14",
        "outputId": "038de006-2f9f-4db0-b94f-84f63f402f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- business_id: string (nullable = true)\n",
            " |-- review: string (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- cool: long (nullable = true)\n",
            " |-- useful: long (nullable = true)\n",
            " |-- funny: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Carga"
      ],
      "metadata": {
        "id": "hNxMjfag9hma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, en esta sección cargamos nuestros datos transformados en formato parquet a su destino correspondiente."
      ],
      "metadata": {
        "id": "o-OnEMti-i2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive"
      ],
      "metadata": {
        "id": "SzJbsgYb-qGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo Parquet local\n",
        "file_path = '/content/drive/MyDrive/data/cleaned/yelp/checkin.parquet'\n",
        "\n",
        "# Escribe el DataFrame a un archivo Parquet localmente\n",
        "df.write.parquet(file_path)\n"
      ],
      "metadata": {
        "id": "t9PEpRX09gVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### S3"
      ],
      "metadata": {
        "id": "0piDPdCm-wRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convierte el DataFrame de Spark a un DynamicFrame de Glue\n",
        "dyf = DynamicFrame.fromDF(df, glueContext, \"dynamic_frame\")"
      ],
      "metadata": {
        "id": "zkDYn1K-2Dr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribe el DynamicFrame a S3 en formato Parquet\n",
        "glueContext.write_dynamic_frame.from_options(\n",
        "    frame = dyf,\n",
        "    connection_type = \"s3\",\n",
        "    connection_options = {\"path\": \"s3://ruta/al/bucket\"},\n",
        "    format = \"parquet\"\n",
        ")"
      ],
      "metadata": {
        "id": "xRDUuquA-4gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}